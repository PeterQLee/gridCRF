* Need to make a seperate linalg module for array selection and whatnot
* TODO Train
Come up with actual updates for train and test with algorithm.
** TODO Experiment with SSE weight updates, see if there is any performance boost.
** TODO Add in l2 norms31

** Make weight update incremental rather than aggregate.

** TODO During training, try reusing the energies from the last iteration. 
This may save some update steps.

* Loopy
** Finish loopy with  marginal evaluation
** DONE Calculate normalizing factor
** DONE fIGURE what is wrong with self->n_factors, it seems to be the only reason the program is segfaulting
   It was bc i forgot header
** DONE Test if setting NPY_ARRAY_OWNDATA will allow memory to be freed after its done.
Not needeed
** TODO Consider transposing V_F and F_V to have channels in higher dimensions like CE and RE
** DONE Check bounds in loopy
** DONE According to intel, mm_malloc must be freed with _mm_free
** DONE Check rom and com

Revise rom and com so they get right columns in direction.
** DONE Find out where nan's are coming from
*** DONE exp 
*** DONE Outside bounds 
*** DONE Softmax 
*** DONE Test the set1_pd(base), might be going out of order?
Works as intended.
*** The coordinate (3, 89) is overflowing first
It is also a pixel on the border, this is probably not a coincidence.
F_V are overflowing

** TODO Change the unary function for linear combination, or none


* GPU Loopy
** Got F_V working exactly the same as CPU
See /mnt/D2/crf_experiments for comparison 


* Results
gpu: 1st iteration

mu
F_V
V_F: 50*100*2*4*2 +50*2*4*2 -> 0

** GPU profiling for test5.py, factor =4
==6244== Profiling application: python3 test5.py
==6244== Profiling result:
Time(%)      Time     Calls       Avg       Min       Max  Name
 36.75%  4.54263s      9907  458.53us  453.86us  566.76us  gpu_loopy_V_F__sumfactors
 27.10%  3.34978s      9907  338.12us  321.00us  774.95us  gpu_loopy_V_F__marginal
 16.93%  2.09239s      9907  211.20us  206.53us  449.77us  gpu_loopy_F_V__Flow
 14.66%  1.81256s      9907  182.96us  180.19us  228.04us  gpu_loopy_F_V__Fup
  2.62%  323.57ms      9907  32.660us  31.360us  42.496us  gpu_loopy_V_F__computeunary
  1.62%  200.44ms     10917  18.360us     480ns  1.5409ms  [CUDA memcpy HtoD]
  0.26%  32.231ms       101  319.12us  313.19us  445.09us  gpu_loopy_V_F__label
  0.07%  8.7026ms     10008     869ns     352ns  15.968us  [CUDA memcpy DtoH]

==6244== API calls:
Time(%)      Time     Calls       Avg       Min       Max  Name
 89.31%  11.7723s     10008  1.1763ms  328.46us  1.8561ms  cudaMemcpy
  2.12%  279.83ms     30731  9.1050us     896ns  209.01ms  cudaStreamCreate
  2.11%  278.25ms     49636  5.6050us  3.2440us  470.95us  cudaLaunch
  2.03%  268.02ms     10917  24.550us  2.9880us  1.6557ms  cudaMemcpyAsync
  1.29%  169.51ms      1313  129.10us  4.3480us  737.10us  cudaMalloc
  1.26%  165.70ms     10917  15.178us     682ns  1.1157ms  cudaStreamSynchronize
  0.73%  96.158ms     30731  3.1290us  1.2900us  115.27us  cudaStreamDestroy
  0.70%  91.894ms      1313  69.988us  3.7750us  458.14us  cudaFree
  0.36%  47.684ms    277800     171ns     115ns  539.37us  cudaSetupArgument
  0.08%  10.821ms     49636     218ns     125ns  124.66us  cudaConfigureCall
  0.00%  587.83us        91  6.4590us     164ns  270.95us  cuDeviceGetAttribute
  0.00%  92.346us         1  92.346us  92.346us  92.346us  cuDeviceTotalMem
  0.00%  41.288us         1  41.288us  41.288us  41.288us  cuDeviceGetName
  0.00%  1.7350us         3     578ns     202ns  1.2590us  cuDeviceGetCount
  0.00%     831ns         3     277ns     211ns     399ns  cuDeviceGet


* gpuweights
[[ 0.04385807 -0.0438581  -0.01280322  0.01280322]
 [ 0.03946958 -0.03946958 -0.0084147   0.0084147 ]
 [ 0.02354451 -0.02354453  0.00751036 -0.00751036]
 [-0.03271274  0.03271274  0.06376766 -0.06376768]
 [ 0.00421229 -0.00421228  0.02684259 -0.02684261]
 [ 0.00934571 -0.0093457   0.02170914 -0.02170916]
 [ 0.01771595 -0.01771595  0.01333896 -0.01333898]
 [ 0.04511145 -0.04511146 -0.01405658  0.01405658]
 [ 0.00641497 -0.00641499  0.02463991 -0.02463991]
 [-0.03567359  0.0356736   0.06672851 -0.06672852]
 [ 0.03635702 -0.03635702 -0.00530211  0.00530211]
 [ 0.02798791 -0.02798791  0.00306697 -0.00306698]
 [-0.00311092  0.00311091  0.03546693 -0.03546694]
 [ 0.00085635 -0.00085636  0.03149967 -0.03149967]
 [ 0.00255939 -0.00255941  0.02979664 -0.02979664]
 [ 0.00076962 -0.00076963  0.03193759 -0.0319376 ]
 [ 0.02472432 -0.02472433  0.00668173 -0.00668174]
 [ 0.04236697 -0.04236697 -0.01096091  0.01096091]
 [ 0.00741277 -0.00741279  0.0239933  -0.02399331]
 [-0.03818579  0.03818579  0.06959183 -0.06959182]
 [ 0.04335582 -0.04335583 -0.01194978  0.01194977]
 [ 0.01846604 -0.01846605  0.01422552 -0.01422552]
 [ 0.02892212 -0.02892212  0.00341827 -0.00341828]
 [ 0.02729156 -0.02729156  0.00504884 -0.00504886]
 [-0.02373769  0.02373769  0.05866237 -0.05866237]
 [-0.0148114   0.01481139  0.04973612 -0.04973611]
 [-0.01021341  0.0102134   0.04513814 -0.04513814]
 [ 0.00561084 -0.00561085  0.02966503 -0.02966505]
 [ 0.01966542 -0.01966544  0.01623576 -0.01623576]
 [-0.00083267  0.00083265  0.03416513 -0.03416513]
 [ 0.01885779 -0.01885779  0.01317358 -0.01317359]
 [ 0.03622592 -0.03622594 -0.00419461  0.0041946 ]
 [ 0.01463586 -0.01463588  0.01739545 -0.01739546]
 [-0.03740055  0.03740055  0.06943192 -0.06943194]
 [ 0.06065067 -0.06065068 -0.02861932  0.02861932]
 [ 0.02728595 -0.02728597  0.0060309  -0.0060309 ]
 [ 0.04168952 -0.04168953 -0.00239828  0.00239827]
 [ 0.04851015 -0.04851015 -0.00984412  0.00984412]
 [ 0.04076911 -0.04076912 -0.0024543   0.0024543 ]
 [ 0.03451028 -0.0345103   0.00380452 -0.00380452]
 [-0.0506331   0.0506331   0.08168793 -0.08168793]
 [-0.03952506  0.03952506  0.07057995 -0.07057998]
 [ 0.0133292  -0.01332921  0.01772569 -0.01772569]
 [ 0.01886293 -0.01886294  0.01219191 -0.01219192]
 [ 0.0278029  -0.02780292  0.00325194 -0.00325195]
 [ 0.02871159 -0.02871161  0.00234328 -0.00234328]
 [ 0.02734177 -0.02734178  0.00371309 -0.0037131 ]
 [-0.02518547  0.02518547  0.05624034 -0.05624037]
 [ 0.02577823 -0.02577824  0.00527665 -0.00527665]
 [ 0.01979648 -0.0197965   0.01125838 -0.01125839]
 [ 0.00051779 -0.0005178   0.03053706 -0.03053708]
 [ 0.00926348 -0.00926349  0.02179144 -0.02179145]
 [ 0.0166457  -0.0166457   0.01569467 -0.01569469]
 [ 0.01818342 -0.01818343  0.01415698 -0.01415698]
 [ 0.00468016 -0.00468016  0.02766026 -0.02766027]
 [-0.00522533  0.00522533  0.03810902 -0.03810903]
 [ 0.01935214 -0.01935215  0.012246   -0.01224601]
 [-0.01260696  0.01260696  0.04420514 -0.04420514]
 [ 0.01507587 -0.01507589  0.01652225 -0.01652225]
 [ 0.02785029 -0.02785029  0.00374782 -0.00374783]
 [ 0.00079308 -0.00079309  0.03080506 -0.03080507]
 [-0.01376416  0.01376415  0.04666341 -0.04666342]
 [-0.01764192  0.01764191  0.04999796 -0.04999795]
 [-0.01620593  0.01620592  0.04856196 -0.04856197]
 [ 0.03149137 -0.03149138  0.00682344 -0.00682345]
 [ 0.02780732 -0.02780734  0.0105075  -0.01050751]
 [ 0.02409399 -0.02409401  0.01422082 -0.01422082]
 [ 0.0212121  -0.02121212  0.01764594 -0.01764595]
 [ 0.02433264 -0.02433265  0.01559878 -0.01559879]
 [-0.01192946  0.01192946  0.04588648 -0.0458865 ]
 [ 0.01401312 -0.01401314  0.01865839 -0.01865839]
 [-0.00267618  0.00267618  0.03534764 -0.03534769]
 [-0.00408777  0.00408776  0.03675921 -0.03675921]
 [ 0.02238349 -0.02238349  0.01028797 -0.01028798]
 [-0.01633449  0.01633448  0.04900594 -0.04900594]
 [-0.01695674  0.01695673  0.05092935 -0.05092936]
 [ 0.01168173 -0.01168174  0.02485958 -0.02485958]
 [-0.00084898  0.00084897  0.03631696 -0.03631698]
 [-0.00749042  0.00749041  0.04241513 -0.04241513]
 [-0.01887376  0.01887375  0.05379847 -0.05379847]]


** cpu weights
[[ 0.04385807 -0.0438581  -0.01280322  0.01280322]
 [ 0.03946958 -0.03946958 -0.0084147   0.0084147 ]
 [ 0.02354451 -0.02354453  0.00751036 -0.00751036]
 [-0.03271274  0.03271274  0.06376766 -0.06376768]
 [ 0.00421229 -0.00421228  0.02684259 -0.02684261]
 [ 0.00934571 -0.0093457   0.02170914 -0.02170916]
 [ 0.01771595 -0.01771595  0.01333896 -0.01333898]
 [ 0.04511145 -0.04511146 -0.01405658  0.01405658]
 [ 0.00641497 -0.00641499  0.02463991 -0.02463991]
 [-0.03567359  0.0356736   0.06672851 -0.06672852]
 [ 0.03635702 -0.03635702 -0.00530211  0.00530211]
 [ 0.02798791 -0.02798791  0.00306697 -0.00306698]
 [-0.00311092  0.00311091  0.03546693 -0.03546694]
 [ 0.00085635 -0.00085636  0.03149967 -0.03149967]
 [ 0.00255939 -0.00255941  0.02979664 -0.02979664]
 [ 0.00076962 -0.00076963  0.03193759 -0.0319376 ]
 [ 0.02472432 -0.02472433  0.00668173 -0.00668174]
 [ 0.04236697 -0.04236697 -0.01096091  0.01096091]
 [ 0.00741277 -0.00741279  0.0239933  -0.02399331]
 [-0.03818579  0.03818579  0.06959183 -0.06959182]
 [ 0.04335582 -0.04335583 -0.01194978  0.01194977]
 [ 0.01846604 -0.01846605  0.01422552 -0.01422552]
 [ 0.02892212 -0.02892212  0.00341827 -0.00341828]
 [ 0.02729156 -0.02729156  0.00504884 -0.00504886]
 [-0.02373769  0.02373769  0.05866237 -0.05866237]
 [-0.0148114   0.01481139  0.04973612 -0.04973611]
 [-0.01021341  0.0102134   0.04513814 -0.04513814]
 [ 0.00561084 -0.00561085  0.02966503 -0.02966505]
 [ 0.01966542 -0.01966544  0.01623576 -0.01623576]
 [-0.00083267  0.00083265  0.03416513 -0.03416513]
 [ 0.01885779 -0.01885779  0.01317358 -0.01317359]
 [ 0.03622592 -0.03622594 -0.00419461  0.0041946 ]
 [ 0.01463586 -0.01463588  0.01739545 -0.01739546]
 [-0.03740055  0.03740055  0.06943192 -0.06943194]
 [ 0.06065067 -0.06065068 -0.02861932  0.02861932]
 [ 0.02728595 -0.02728597  0.0060309  -0.0060309 ]
 [ 0.04168952 -0.04168953 -0.00239828  0.00239827]
 [ 0.04851015 -0.04851015 -0.00984412  0.00984412]
 [ 0.04076911 -0.04076912 -0.0024543   0.0024543 ]
 [ 0.03451028 -0.0345103   0.00380452 -0.00380452]
 [-0.0506331   0.0506331   0.08168793 -0.08168793]
 [-0.03952506  0.03952506  0.07057995 -0.07057998]
 [ 0.0133292  -0.01332921  0.01772569 -0.01772569]
 [ 0.01886293 -0.01886294  0.01219191 -0.01219192]
 [ 0.0278029  -0.02780292  0.00325194 -0.00325195]
 [ 0.02871159 -0.02871161  0.00234328 -0.00234328]
 [ 0.02734177 -0.02734178  0.00371309 -0.0037131 ]
 [-0.02518547  0.02518547  0.05624034 -0.05624037]
 [ 0.02577823 -0.02577824  0.00527665 -0.00527665]
 [ 0.01979648 -0.0197965   0.01125838 -0.01125839]
 [ 0.00051779 -0.0005178   0.03053706 -0.03053708]
 [ 0.00926348 -0.00926349  0.02179144 -0.02179145]
 [ 0.0166457  -0.0166457   0.01569467 -0.01569469]
 [ 0.01818342 -0.01818343  0.01415698 -0.01415698]
 [ 0.00468016 -0.00468016  0.02766026 -0.02766027]
 [-0.00522533  0.00522533  0.03810902 -0.03810903]
 [ 0.01935214 -0.01935215  0.012246   -0.01224601]
 [-0.01260696  0.01260696  0.04420514 -0.04420514]
 [ 0.01507587 -0.01507589  0.01652225 -0.01652225]
 [ 0.02785029 -0.02785029  0.00374782 -0.00374783]
 [ 0.00079308 -0.00079309  0.03080506 -0.03080507]
 [-0.01376416  0.01376415  0.04666341 -0.04666342]
 [-0.01764192  0.01764191  0.04999796 -0.04999795]
 [-0.01620593  0.01620592  0.04856196 -0.04856197]
 [ 0.03149137 -0.03149138  0.00682344 -0.00682345]
 [ 0.02780732 -0.02780734  0.0105075  -0.01050751]
 [ 0.02409399 -0.02409401  0.01422082 -0.01422082]
 [ 0.0212121  -0.02121212  0.01764594 -0.01764595]
 [ 0.02433264 -0.02433265  0.01559878 -0.01559879]
 [-0.01192946  0.01192946  0.04588648 -0.0458865 ]
 [ 0.01401312 -0.01401314  0.01865839 -0.01865839]
 [-0.00267618  0.00267618  0.03534764 -0.03534769]
 [-0.00408777  0.00408776  0.03675921 -0.03675921]
 [ 0.02238349 -0.02238349  0.01028797 -0.01028798]
 [-0.01633449  0.01633448  0.04900594 -0.04900594]
 [-0.01695674  0.01695673  0.05092935 -0.05092936]
 [ 0.01168173 -0.01168174  0.02485958 -0.02485958]
 [-0.00084898  0.00084897  0.03631696 -0.03631698]
 [-0.00749042  0.00749041  0.04241513 -0.04241513]
 [-0.01887376  0.01887375  0.05379847 -0.05379847]]


* Ensure that input is C aligned memory.


* Dice error training

** DONE allocate error data for dice in both cpu and gpu

** TODO Finish gpu implementation

** TODO test
** TODO  Warning, watch out for nans, these could occur when sum = 0

* DONE Fix rmsp current offset in CPU to do it at the end of epoch.\

* TODO Fix numpy owned 
* TODO universalize linalg operations
